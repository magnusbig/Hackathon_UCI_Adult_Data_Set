{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest & Bagged Decision Tree Optimization Comparison\n",
    "\n",
    "Notebook performing hyperparameter optimization on Random Forest and Bagged Decision Tree models to improve performance and see if they can be our main model.\n",
    "\n",
    "Magnus Bigelow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- [Imports](#Imports)\n",
    "- [Useful Functions](#Useful-Functions)\n",
    "- [Bagged Decision Tree](#Bagged-Decision-Tree)\n",
    "- [Random Forest](#Random-Forest)\n",
    "- [AdaBoost](#AdaBoost)\n",
    "- [Voting Classifier](#Voting-Classifier)\n",
    "- [Voting Classifier w/KNN](#Voting-Classifier-w/KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# General Modeling Imports \n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# Classification models\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier,  AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/clean_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education-num</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>wage</th>\n",
       "      <th>marital_status_num</th>\n",
       "      <th>occupation_com_House_Services</th>\n",
       "      <th>occupation_com_Other</th>\n",
       "      <th>occupation_com_Professional</th>\n",
       "      <th>occupation_com_Specialty</th>\n",
       "      <th>occupation_com_Tech/sales</th>\n",
       "      <th>workclass_com_ Government</th>\n",
       "      <th>workclass_com_ Other</th>\n",
       "      <th>workclass_com_ Private</th>\n",
       "      <th>workclass_com_ Self-employed</th>\n",
       "      <th>cap_gain_binary</th>\n",
       "      <th>cap_loss_binary</th>\n",
       "      <th>gdp_pc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41524.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41524.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41524.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41524.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12492.097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  education-num  sex  capital-gain  capital-loss  hours-per-week  wage  \\\n",
       "0   39             13    1          2174             0              40     0   \n",
       "1   50             13    1             0             0              13     0   \n",
       "2   38              9    1             0             0              40     0   \n",
       "3   53              7    1             0             0              40     0   \n",
       "4   28             13    1             0             0              40     0   \n",
       "\n",
       "   marital_status_num  occupation_com_House_Services  occupation_com_Other  \\\n",
       "0                   0                              0                     1   \n",
       "1                   1                              0                     0   \n",
       "2                   0                              1                     0   \n",
       "3                   1                              1                     0   \n",
       "4                   1                              0                     0   \n",
       "\n",
       "   occupation_com_Professional  occupation_com_Specialty  \\\n",
       "0                            0                         0   \n",
       "1                            1                         0   \n",
       "2                            0                         0   \n",
       "3                            0                         0   \n",
       "4                            1                         0   \n",
       "\n",
       "   occupation_com_Tech/sales  workclass_com_ Government  workclass_com_ Other  \\\n",
       "0                          0                          1                     0   \n",
       "1                          0                          0                     0   \n",
       "2                          0                          0                     0   \n",
       "3                          0                          0                     0   \n",
       "4                          0                          0                     0   \n",
       "\n",
       "   workclass_com_ Private  workclass_com_ Self-employed  cap_gain_binary  \\\n",
       "0                       0                             0                1   \n",
       "1                       0                             1                0   \n",
       "2                       1                             0                0   \n",
       "3                       1                             0                0   \n",
       "4                       1                             0                0   \n",
       "\n",
       "   cap_loss_binary     gdp_pc  \n",
       "0                0  41524.090  \n",
       "1                0  41524.090  \n",
       "2                0  41524.090  \n",
       "3                0  41524.090  \n",
       "4                0  12492.097  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print train and test F1 score\n",
    "def f1(model, X_train, y_train, X_test, y_test):\n",
    "    y_train_p = model.predict(X_train)\n",
    "    y_test_p = model.predict(X_test)\n",
    "    f_train = f1_score(y_train,y_train_p)\n",
    "    f_test = f1_score(y_test,y_test_p)\n",
    "    print(f'Train F1: {round(f_train,3)}')\n",
    "    print(f'Test F1: {round(f_test,3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate and display classification metrics, works for bernoulli y\n",
    "def class_metrics(model, X, y):\n",
    "    # Generate predictions\n",
    "    preds = model.predict(X)\n",
    "    # Get confusion matrix and unravel\n",
    "    tn, fp, fn, tp = confusion_matrix(y,preds).ravel()\n",
    "    # Accuracy\n",
    "    print(f'Accuracy: {round((tp+tn)/len(y),3)}')\n",
    "    # Sensitivity\n",
    "    print(f'Sensitivity: {round(tp/(tp+fn),3)}')\n",
    "    # Specificity\n",
    "    print(f'Specificity: {round(tn/(tn+fp),3)}')\n",
    "    # Precision\n",
    "    print(f'Precision: {round(tp/(tp+fp),3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up X and Y\n",
    "X = train[['age', 'education-num', 'sex', \n",
    "       'hours-per-week', 'marital_status_num',\n",
    "       'occupation_com_House_Services', 'occupation_com_Professional',\n",
    "       'occupation_com_Specialty','occupation_com_Tech/sales', \n",
    "       'workclass_com_ Government','workclass_com_ Private',\n",
    "       'workclass_com_ Self-employed', 'cap_gain_binary', \n",
    "       'cap_loss_binary','gdp_pc']]\n",
    "y = train['wage']\n",
    "\n",
    "# Split the data into the training and testing sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state=33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagged Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the bagged decision tree most of the hyperparameters that we can tune will make it more like a random forest, as such we will try different values for the n_estimators but otherwise leave the model as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter: {'n_estimators': 250}\n",
      "\n",
      "Train F1: 0.91\n",
      "Test F1: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Adapted from GA DSI Lesson 6.03\n",
    "bt = BaggingClassifier(random_state=33)\n",
    "bt_params = {\n",
    "    'n_estimators': [50, 100, 250],\n",
    "}\n",
    "\n",
    "bt_gs = GridSearchCV(bt, \n",
    "                  param_grid=bt_params,\n",
    "                  cv=5,\n",
    "                  n_jobs=2)\n",
    "\n",
    "bt_gs.fit(X_train,y_train)\n",
    "\n",
    "# Show metrics and best parameters\n",
    "print(f'Best hyperparameter: {bt_gs.best_params_}\\n')\n",
    "f1(bt_gs,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.816\n",
      "Sensitivity: 0.574\n",
      "Specificity: 0.892\n",
      "Precision: 0.629\n"
     ]
    }
   ],
   "source": [
    "class_metrics(bt_gs,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our bagged decision tree model improved it's performance from the baseline model we ran:\n",
    "- Train F1: 0.888 -> 0.91\n",
    "- Test F1: 0.581 -> 0.6\n",
    "\n",
    "We can see from the test metrics that it is doing a great job of classifying negative cases but not a good job of classifying positive cases, which is expected given our imbalanced classes. \n",
    "\n",
    "This increase in performance comes at the cost of running 250 tree models instead of the baseline 10 models and means that even if we ran infinite models it is unlikely that our performance would improve much. Let's look at the Random Forest Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the random forest we will attempt a higher number of estimators, play with the max_depth (i.e. how many nodes down / how many features each model uses), warm_start (let's the model learn from the previous model to continue improving) and min_samples_leaf which is the number of samples that need to be at the end of each leaf node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter: {'max_depth': 11, 'min_samples_leaf': 5, 'n_estimators': 100, 'warm_start': True}\n",
      "\n",
      "Train F1: 0.657\n",
      "Test F1: 0.635\n"
     ]
    }
   ],
   "source": [
    "# Adapted from GA DSI Lesson 6.03\n",
    "rf = RandomForestClassifier(random_state=33)\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 125],\n",
    "    'max_depth': [None, 3, 7, 11],\n",
    "    'warm_start': [True,False],\n",
    "    'min_samples_leaf': [1, 5]\n",
    "    \n",
    "}\n",
    "\n",
    "rf_gs = GridSearchCV(rf, \n",
    "                  param_grid=rf_params,\n",
    "                  cv=5,\n",
    "                  n_jobs=2)\n",
    "\n",
    "rf_gs.fit(X_train,y_train)\n",
    "\n",
    "# Show metrics and best parameters\n",
    "print(f'Best hyperparameter: {rf_gs.best_params_}\\n')\n",
    "f1(rf_gs,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.847\n",
      "Sensitivity: 0.552\n",
      "Specificity: 0.941\n",
      "Precision: 0.748\n"
     ]
    }
   ],
   "source": [
    "class_metrics(rf_gs,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best random forrest model used a max_depth of 11, min_samples_leaf of 5, standard number of estimators and a warm_start.\n",
    "\n",
    "We got a test accuracy of 0.847 and a test F1 of 0.635 which is an improvement on our completely standard F1 score and on the bagged decision tree.\n",
    "\n",
    "While the train F1 score went down this is good as our model is no longer severely overfit and we can trust it's performance on new data more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the AdaBoost model we will attempt with the default 50 estimators and also with 100 estimators.  Additionally we will play around with the learning rate which weights subsequent trees differently when making predictions to try to improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameter: {'learning_rate': 1, 'n_estimators': 50}\n",
      "\n",
      "Train F1: 0.641\n",
      "Test F1: 0.646\n"
     ]
    }
   ],
   "source": [
    "# Adapted from GA DSI Lesson 6.03\n",
    "ab = AdaBoostClassifier(random_state=33)\n",
    "ab_params = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'learning_rate': [1, .5, 1.5]\n",
    "}\n",
    "\n",
    "ab_gs = GridSearchCV(ab, \n",
    "                  param_grid=ab_params,\n",
    "                  cv=5,\n",
    "                  n_jobs=2)\n",
    "\n",
    "ab_gs.fit(X_train,y_train)\n",
    "\n",
    "# Show metrics and best parameters\n",
    "print(f'Best hyperparameter: {ab_gs.best_params_}\\n')\n",
    "f1(ab_gs,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.847\n",
      "Sensitivity: 0.581\n",
      "Specificity: 0.931\n",
      "Precision: 0.727\n"
     ]
    }
   ],
   "source": [
    "class_metrics(ab_gs,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best AdaBoost model ended up being the default model and it is our best one so far. The train Accuracy was 0.847 and the test F1 score is 0.646 which is our highest yet. \n",
    "\n",
    "The F1 is still low because we have unbalanced classes and are poor at predicting the positive case. \n",
    "\n",
    "Let's try a voting classifier using the 3 models we've fit above and the best hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.682\n",
      "Test F1: 0.639\n"
     ]
    }
   ],
   "source": [
    "vote = VotingClassifier([\n",
    "            ('bt',BaggingClassifier(random_state=33)),\n",
    "            ('rf',RandomForestClassifier(random_state=33, max_depth=11, min_samples_leaf=5)),\n",
    "            ('ab',AdaBoostClassifier(random_state=33, n_estimators=50)) \n",
    "])\n",
    "\n",
    "# Fit \n",
    "vote.fit(X_train,y_train)\n",
    "\n",
    "# Show metrics \n",
    "f1(vote,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.847\n",
      "Sensitivity: 0.562\n",
      "Specificity: 0.938\n",
      "Precision: 0.741\n"
     ]
    }
   ],
   "source": [
    "class_metrics(vote,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our voting classifier performs slightly better than our AdaBoost model on the Training set, however, it performs more poorly on the testing set. This may be a result of noise in the training and testing set but for now the AdaBoost is still our best model. Perhaps adding a logistic regression and knn to the voting classifier would result in a superior score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier w/KNN\n",
    "\n",
    "During my partners analysis he found a knn model with n_neighbors = 25 which had a higher sensitivity than any of the models in this notebook and had similar F1 and accuracy scores to our best models. As a result we will also try replacing the Bagged Trees model in our voting classifier (as it was the worst performing model) with a KNN classifier with n_neighbors = 25 and see if the results improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.644\n",
      "Test F1: 0.635\n"
     ]
    }
   ],
   "source": [
    "vote = VotingClassifier([\n",
    "            ('knn',KNeighborsClassifier(n_neighbors=25)),\n",
    "            ('rf',RandomForestClassifier(random_state=33, max_depth=11, min_samples_leaf=5)),\n",
    "            ('ab',AdaBoostClassifier(random_state=33, n_estimators=50)) \n",
    "])\n",
    "\n",
    "# Fit \n",
    "vote.fit(X_train,y_train)\n",
    "\n",
    "# Show metrics \n",
    "f1(vote,X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.847\n",
      "Sensitivity: 0.551\n",
      "Specificity: 0.941\n",
      "Precision: 0.749\n"
     ]
    }
   ],
   "source": [
    "class_metrics(vote,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The voting classifier with the KNN model is actually slightly worse than the previous voting classifier and as a result we will go forward with the KNN model as our primary model, not using any of the models on this notebook. While the KNN model isn't clearly superior to the other models the higher sensitivity is desireable when we have unbalanced classes like we do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
